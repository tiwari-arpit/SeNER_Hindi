{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tiwari-arpit/SeNER_Hindi/blob/main/SeNER_Hindi.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "PHGqiyd1sm6Y"
      },
      "outputs": [],
      "source": [
        "# Hugging Face datasets package\n",
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "cluUA_urqDbK"
      },
      "outputs": [],
      "source": [
        "# Libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import AutoModel, AutoConfig, AutoModelForTokenClassification, AutoTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "OeJUAqKxrUxX"
      },
      "outputs": [],
      "source": [
        "# base model distilbert finetuned for hindi ner (https://huggingface.co/arpit-tiwari/distilbert-finetuned-hindi-ner)\n",
        "model_name = \"arpit-tiwari/distilbert-finetuned-hindi-ner\"\n",
        "model_checkpoint = AutoModelForTokenClassification.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "laiG0DN4sE-C"
      },
      "outputs": [],
      "source": [
        "# Dataset naamapadam from ai4bharat (https://huggingface.co/datasets/ai4bharat/naamapadam)\n",
        "from datasets import load_dataset\n",
        "lang = 'hi'\n",
        "data = load_dataset('ai4bharat/naamapadam',lang)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "0FhlkdsFHU-r",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "71160a74-3700-4e72-9bdc-6e3e225dceec"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              tokens  \\\n",
              "0  [एशियन, पेंट्स, भारत, की, सबसे, बडी, और, एशिया...   \n",
              "1  [इसके, जवाब, में, ट्रंप, ने, कहा, कि, वह, एक, ...   \n",
              "2  [भारत, एक, बहुभाषी, देश, है, और, संविधान, के, ...   \n",
              "3  [प्रधानमंत्री, ने, एशिया, प्रशांत, क्षेत्र, के...   \n",
              "4  [जबकि, अंदरूनी, सुविधाओं, में, एक, बहु, -, स्त...   \n",
              "\n",
              "                                            ner_tags  \n",
              "0  [3, 4, 5, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, ...  \n",
              "1  [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
              "2  [5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
              "3  [0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, ...  \n",
              "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ed8d9d5f-9a8f-407a-8bc9-0beda5aafe16\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tokens</th>\n",
              "      <th>ner_tags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[एशियन, पेंट्स, भारत, की, सबसे, बडी, और, एशिया...</td>\n",
              "      <td>[3, 4, 5, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[इसके, जवाब, में, ट्रंप, ने, कहा, कि, वह, एक, ...</td>\n",
              "      <td>[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[भारत, एक, बहुभाषी, देश, है, और, संविधान, के, ...</td>\n",
              "      <td>[5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[प्रधानमंत्री, ने, एशिया, प्रशांत, क्षेत्र, के...</td>\n",
              "      <td>[0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[जबकि, अंदरूनी, सुविधाओं, में, एक, बहु, -, स्त...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ed8d9d5f-9a8f-407a-8bc9-0beda5aafe16')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ed8d9d5f-9a8f-407a-8bc9-0beda5aafe16 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ed8d9d5f-9a8f-407a-8bc9-0beda5aafe16');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-08ce0494-c211-410d-8e1e-04f5fd2d2aa6\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-08ce0494-c211-410d-8e1e-04f5fd2d2aa6')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-08ce0494-c211-410d-8e1e-04f5fd2d2aa6 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"hindi_data['train']\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"tokens\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ner_tags\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "# Training on only first 100000 samples; trained on 50000 samples at a time recursively.\n",
        "hindi_data = data\n",
        "hindi_data['train'] = data['train'].select(range(50000,100001))\n",
        "hindi_data['train'].to_pandas().head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "w7pIqLXYsbUo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "2ea380d5-8395-4844-c100-010cb005dccf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              tokens  \\\n",
              "0  [एशियन, पेंट्स, भारत, की, सबसे, बडी, और, एशिया...   \n",
              "1  [इसके, जवाब, में, ट्रंप, ने, कहा, कि, वह, एक, ...   \n",
              "2  [भारत, एक, बहुभाषी, देश, है, और, संविधान, के, ...   \n",
              "3  [प्रधानमंत्री, ने, एशिया, प्रशांत, क्षेत्र, के...   \n",
              "4  [जबकि, अंदरूनी, सुविधाओं, में, एक, बहु, -, स्त...   \n",
              "\n",
              "                                            ner_tags  \\\n",
              "0  [3, 4, 5, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, ...   \n",
              "1  [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
              "2  [5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
              "3  [0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, ...   \n",
              "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
              "\n",
              "                                        ner_tags_str  \n",
              "0  [B-ORG, I-ORG, B-LOC, O, O, O, O, B-LOC, O, O,...  \n",
              "1  [O, O, O, B-PER, O, O, O, O, O, O, O, O, O, O,...  \n",
              "2  [B-LOC, O, O, O, O, O, O, O, O, O, O, O, O, O,...  \n",
              "3  [O, O, B-LOC, O, O, O, O, O, O, O, O, O, O, O,...  \n",
              "4  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4baa1f50-38f8-4ff4-a394-63d89bc09c44\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tokens</th>\n",
              "      <th>ner_tags</th>\n",
              "      <th>ner_tags_str</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[एशियन, पेंट्स, भारत, की, सबसे, बडी, और, एशिया...</td>\n",
              "      <td>[3, 4, 5, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>[B-ORG, I-ORG, B-LOC, O, O, O, O, B-LOC, O, O,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[इसके, जवाब, में, ट्रंप, ने, कहा, कि, वह, एक, ...</td>\n",
              "      <td>[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>[O, O, O, B-PER, O, O, O, O, O, O, O, O, O, O,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[भारत, एक, बहुभाषी, देश, है, और, संविधान, के, ...</td>\n",
              "      <td>[5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>[B-LOC, O, O, O, O, O, O, O, O, O, O, O, O, O,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[प्रधानमंत्री, ने, एशिया, प्रशांत, क्षेत्र, के...</td>\n",
              "      <td>[0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, ...</td>\n",
              "      <td>[O, O, B-LOC, O, O, O, O, O, O, O, O, O, O, O,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[जबकि, अंदरूनी, सुविधाओं, में, एक, बहु, -, स्त...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4baa1f50-38f8-4ff4-a394-63d89bc09c44')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4baa1f50-38f8-4ff4-a394-63d89bc09c44 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4baa1f50-38f8-4ff4-a394-63d89bc09c44');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a69c3a7b-c614-4369-aa94-726ac407fbd5\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a69c3a7b-c614-4369-aa94-726ac407fbd5')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a69c3a7b-c614-4369-aa94-726ac407fbd5 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"hindi_data['train']\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"tokens\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ner_tags\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ner_tags_str\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "# Genearting tag names for numerical labels\n",
        "tags = hindi_data['train'].features['ner_tags'].feature\n",
        "def create_tag_name(batch):\n",
        "  tag_name = {'ner_tags_str': [ tags.int2str(idx) for idx in batch['ner_tags']]}\n",
        "  return tag_name\n",
        "\n",
        "hindi_data = hindi_data.map(create_tag_name)\n",
        "hindi_data['train'].to_pandas().head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L7Q1DE13thBn"
      },
      "outputs": [],
      "source": [
        "# Tokenizing and aligning lables (BERT uses subword tokenization (example \"hello\" may be tokenized as \"hell\",\"##o\"), thus we need to align tags accordingly)\n",
        "def tokenize_and_align_labels(examples):\n",
        "    tokenized_inputs = tokenizer(examples[\"tokens\"], truncation=True, is_split_into_words=True)\n",
        "    labels = []\n",
        "    for i, label in enumerate(examples[\"ner_tags\"]):\n",
        "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
        "        previous_word_idx = None\n",
        "        label_ids = []\n",
        "        for word_idx in word_ids:\n",
        "            if word_idx is None:\n",
        "                label_ids.append(-100)\n",
        "            elif word_idx != previous_word_idx:\n",
        "                label_ids.append(label[word_idx])\n",
        "            else:\n",
        "                label_ids.append(-100)\n",
        "            previous_word_idx = word_idx\n",
        "        labels.append(label_ids)\n",
        "    tokenized_inputs[\"labels\"] = labels\n",
        "    return tokenized_inputs\n",
        "\n",
        "tokenized_dataset = hindi_data.map(tokenize_and_align_labels,batched=True,remove_columns=hindi_data['train'].column_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "QarwTP-lpnNL"
      },
      "outputs": [],
      "source": [
        "# ArrowAttention Mechanism\n",
        "class ArrowAttention(nn.Module):\n",
        "    def __init__(self, hidden_size, window_size, num_heads=8):\n",
        "        super().__init__()\n",
        "        self.window_size = window_size\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = hidden_size // num_heads\n",
        "        self.cls_attention = nn.MultiheadAttention(hidden_size, num_heads)\n",
        "        self.local_attention = nn.MultiheadAttention(hidden_size, num_heads)\n",
        "\n",
        "    def forward(self, hidden_states):\n",
        "        batch_size, seq_len, hidden_size = hidden_states.size()\n",
        "\n",
        "        cls_token = hidden_states[:, 0:1, :] # Extract [cls] token\n",
        "        cls_token = cls_token.transpose(0, 1)\n",
        "        # Apply Global Attention\n",
        "        global_output, _ = self.cls_attention(\n",
        "            cls_token,\n",
        "            hidden_states.transpose(0, 1),\n",
        "            hidden_states.transpose(0, 1)\n",
        "        )\n",
        "        global_output = global_output.transpose(0, 1)\n",
        "\n",
        "        if seq_len > 1: # If any input text apply Local Attention\n",
        "            local_outputs = []\n",
        "            for i in range(1, seq_len):\n",
        "                start = max(1, i - self.window_size)\n",
        "                end = min(seq_len, i + self.window_size + 1)\n",
        "\n",
        "                window = hidden_states[:, start:end, :]\n",
        "                current_token = hidden_states[:, i:i+1, :]\n",
        "\n",
        "                current_token = current_token.transpose(0, 1)\n",
        "                window = window.transpose(0, 1)\n",
        "\n",
        "                local_output, _ = self.local_attention(\n",
        "                    current_token,\n",
        "                    window,\n",
        "                    window\n",
        "                )\n",
        "                local_output = local_output.transpose(0, 1)\n",
        "                local_outputs.append(local_output)\n",
        "\n",
        "            if local_outputs: # Combine local and global attention outputs\n",
        "                local_output = torch.cat(local_outputs, dim=1)\n",
        "                output = torch.cat([global_output, local_output], dim=1)\n",
        "            else:\n",
        "                output = global_output\n",
        "        else:\n",
        "            output = global_output\n",
        "\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "OKDb56R7qRV9"
      },
      "outputs": [],
      "source": [
        "# Apply LogNScaling (only applying scaling by divind attention score by head_size)\n",
        "class LogNScaling(nn.Module):\n",
        "    def __init__(self, hidden_size):\n",
        "        super(LogNScaling, self).__init__()\n",
        "        self.scale = nn.Parameter(torch.tensor(1.0 / (hidden_size ** 0.5)))\n",
        "\n",
        "    def forward(self, attention_scores):\n",
        "        return attention_scores * self.scale"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "kcf4VbTQqSC7"
      },
      "outputs": [],
      "source": [
        "# Apply BiDirectional Sliding Window Plus Attention to encode candidate token's interaction\n",
        "class BiSPA(nn.Module):\n",
        "    def __init__(self, hidden_size, window_size, num_heads=8):\n",
        "        super(BiSPA, self).__init__()\n",
        "        self.window_size = window_size\n",
        "        self.num_heads = num_heads\n",
        "        self.horizontal_attention = nn.MultiheadAttention(hidden_size, num_heads)\n",
        "        self.vertical_attention = nn.MultiheadAttention(hidden_size, num_heads)\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(2 * hidden_size, hidden_size),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_size, hidden_size)\n",
        "        )\n",
        "\n",
        "    def forward(self, hidden_states):\n",
        "        batch_size, seq_len, hidden_size = hidden_states.size()\n",
        "        hidden_states_t = hidden_states.transpose(0, 1)\n",
        "\n",
        "        # Horizontal attention\n",
        "        horizontal_outputs = []\n",
        "        for i in range(seq_len):\n",
        "            start = max(0, i - self.window_size)\n",
        "            end = min(seq_len, i + self.window_size + 1)\n",
        "            horizontal_input = hidden_states_t[start:end, :, :]\n",
        "            query = hidden_states_t[i:i+1, :, :]\n",
        "\n",
        "            horizontal_output, _ = self.horizontal_attention(\n",
        "                query,\n",
        "                horizontal_input,\n",
        "                horizontal_input\n",
        "            )\n",
        "            horizontal_outputs.append(horizontal_output)\n",
        "\n",
        "        horizontal_output = torch.cat(horizontal_outputs, dim=0)\n",
        "\n",
        "        # Vertical attention\n",
        "        vertical_outputs = []\n",
        "        for i in range(seq_len):\n",
        "            query = hidden_states_t[i:i+1, :, :]\n",
        "            vertical_output, _ = self.vertical_attention(\n",
        "                query,\n",
        "                hidden_states_t,\n",
        "                hidden_states_t\n",
        "            )\n",
        "            vertical_outputs.append(vertical_output)\n",
        "\n",
        "        vertical_output = torch.cat(vertical_outputs, dim=0)\n",
        "\n",
        "        # Combine outputs\n",
        "        combined_output = torch.cat([horizontal_output, vertical_output], dim=-1)\n",
        "        output = self.mlp(combined_output)\n",
        "        output = output.transpose(0, 1)\n",
        "\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "f6KpG1b5qW9q"
      },
      "outputs": [],
      "source": [
        "# Language Model\n",
        "class SeNER(nn.Module):\n",
        "    def __init__(self, model_name, num_labels, window_size=128):\n",
        "        super(SeNER, self).__init__()\n",
        "        self.config = AutoConfig.from_pretrained(model_name) # Config of base model\n",
        "        self.base_model = AutoModel.from_pretrained(model_name, config=self.config)  # base model\n",
        "        self.num_labels = num_labels\n",
        "        self.arrow_attention = ArrowAttention(self.config.hidden_size, window_size) # Arrow Attention\n",
        "        self.log_n_scaling = LogNScaling(self.config.hidden_size) # LogNScaling\n",
        "        self.bispa = BiSPA(self.config.hidden_size, window_size)  # BiDirectional Sliding Window Plus Attention\n",
        "        self.classifier = nn.Linear(self.config.hidden_size, num_labels) # Applying classification (output layer)\n",
        "        self.dropout = nn.Dropout(self.config.hidden_size_dropout if hasattr(self.config, 'hidden_size_dropout') else 0.1) # Applying Dropout to avois overfitting\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, labels=None):\n",
        "        outputs = self.base_model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        sequence_output = outputs.last_hidden_state\n",
        "\n",
        "        attended_output = self.arrow_attention(sequence_output)\n",
        "\n",
        "        if attended_output.size(1) > 0:\n",
        "            cls_token = attended_output[:, 0:1, :]\n",
        "            scaled_cls = self.log_n_scaling(cls_token)\n",
        "\n",
        "            if attended_output.size(1) > 1:\n",
        "                attended_output = torch.cat([scaled_cls, attended_output[:, 1:, :]], dim=1)\n",
        "            else:\n",
        "                attended_output = scaled_cls\n",
        "\n",
        "        sequence_output = self.bispa(attended_output)\n",
        "        sequence_output = self.dropout(sequence_output)\n",
        "        logits = self.classifier(sequence_output)\n",
        "\n",
        "        loss = None # Define Loss function, using CrossEntopyLoss\n",
        "        if labels is not None:\n",
        "            loss_fct = nn.CrossEntropyLoss()\n",
        "            active_loss = labels.view(-1) != -100\n",
        "            active_logits = logits.view(-1, self.num_labels)[active_loss]\n",
        "            active_labels = labels.view(-1)[active_loss]\n",
        "            loss = loss_fct(active_logits, active_labels)\n",
        "\n",
        "        return {'loss': loss, 'logits': logits} if loss is not None else {'logits': logits}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "HclmJ5blxtEl"
      },
      "outputs": [],
      "source": [
        "# Datacollator ata collators can handle tasks like padding sequences to the same length, applying random data augmentation,\n",
        "# or preparing data for specific tasks like language modeling or token classification.\n",
        "# It simplifyies the preprocessing pipeline and make it easier to work with datasets of varying sizes and formats.\n",
        "\n",
        "from transformers import DataCollatorForTokenClassification\n",
        "data_colator = DataCollatorForTokenClassification(tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mCEX8Zm2XhVq",
        "outputId": "21f08f87-2e67-4778-8dda-9d74aabb5307"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Mounting google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "36WHbdSNIZE0",
        "outputId": "6d7371fe-3484-4a8e-cf86-b380cf27d12c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['content']"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Extracting zip file (as we are training model recursively, we save model weights and later load saved state)\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "# if not os.path.exists(extract_dir):\n",
        "#     os.makedirs(extract_dir)\n",
        "\n",
        "with zipfile.ZipFile(\"/content/MyDrive/MyDrive/SeNER.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"extract_dir\")\n",
        "\n",
        "os.listdir(\"/content/extract_dir/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3s4NGHr1beFI",
        "outputId": "76ef1861-3c00-48f8-de7c-0e558a5d4157"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['special_tokens_map.json',\n",
              " 'tokenizer_config.json',\n",
              " 'training_args.bin',\n",
              " 'vocab.txt',\n",
              " 'tokenizer.json',\n",
              " 'model.safetensors']"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "# Listing files in SeNER Dircetory\n",
        "import os\n",
        "os.listdir(\"drive/MyDrive/nlp/SeNER/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DRaRBYDJ_7fc",
        "outputId": "4dd079f5-9811-4968-c040-5b2233373883"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ClassLabel(names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC'], id=None)"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Entities available in dataset\n",
        "tags"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "RdnnDXosqt3T"
      },
      "outputs": [],
      "source": [
        "# Initializing number of labels and model\n",
        "num_labels = len(tags.names)\n",
        "model = SeNER(model_name, num_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y6z0noFybu0B",
        "outputId": "144e00d1-4f51-4be0-ea41-b6a801d35bc4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SeNER(\n",
              "  (base_model): DistilBertModel(\n",
              "    (embeddings): Embeddings(\n",
              "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (transformer): Transformer(\n",
              "      (layer): ModuleList(\n",
              "        (0-5): 6 x TransformerBlock(\n",
              "          (attention): DistilBertSdpaAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (activation): GELUActivation()\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (arrow_attention): ArrowAttention(\n",
              "    (cls_attention): MultiheadAttention(\n",
              "      (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "    )\n",
              "    (local_attention): MultiheadAttention(\n",
              "      (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "    )\n",
              "  )\n",
              "  (log_n_scaling): LogNScaling()\n",
              "  (bispa): BiSPA(\n",
              "    (horizontal_attention): MultiheadAttention(\n",
              "      (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "    )\n",
              "    (vertical_attention): MultiheadAttention(\n",
              "      (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "    )\n",
              "    (mlp): Sequential(\n",
              "      (0): Linear(in_features=1536, out_features=768, bias=True)\n",
              "      (1): ReLU()\n",
              "      (2): Linear(in_features=768, out_features=768, bias=True)\n",
              "    )\n",
              "  )\n",
              "  (classifier): Linear(in_features=768, out_features=7, bias=True)\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "# Loading saved model weights\n",
        "from safetensors.torch import load_file\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # If GPU avalibale use it\n",
        "\n",
        "state_dict = load_file(\"drive/MyDrive/nlp/SeNER/model.safetensors\")\n",
        "model.load_state_dict(state_dict)\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CMB78Qk9qudl"
      },
      "outputs": [],
      "source": [
        "# Initializing training args\n",
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./SeNER_Hindi\",\n",
        "    per_device_train_batch_size=4,\n",
        "    per_device_eval_batch_size=4,\n",
        "    eval_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    num_train_epochs=1,\n",
        "    weight_decay=0.01,\n",
        "    remove_unused_columns=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EtIzqx1ZqulW"
      },
      "outputs": [],
      "source": [
        "# training\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset[\"train\"],\n",
        "    eval_dataset=tokenized_dataset[\"test\"],\n",
        "    data_collator = data_colator,\n",
        ")\n",
        "\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pGaO0vaLqzap"
      },
      "outputs": [],
      "source": [
        "# evaluate training\n",
        "results = trainer.evaluate()\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N_DqYoq17Brj"
      },
      "outputs": [],
      "source": [
        "trainer.save_model(\"./SeNER\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "6EQoFPWC_xuV"
      },
      "outputs": [],
      "source": [
        "# Function for tokenizing text input, aligning labels and generating tags\n",
        "def predict_entities(model, tokenizer, text, id2label=None):\n",
        "    inputs = tokenizer(text, return_offsets_mapping=True, return_tensors=\"pt\", truncation=True, padding=True)\n",
        "    offset_mapping = inputs.pop(\"offset_mapping\")\n",
        "    inputs = {k: v.to(next(model.parameters()).device) for k, v in inputs.items()}\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "    logits = outputs[\"logits\"]\n",
        "    predictions = torch.argmax(logits, dim=-1)[0].cpu().numpy()\n",
        "    tokens = tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0])\n",
        "    offset_mapping = offset_mapping[0].cpu().numpy()\n",
        "\n",
        "    word_entities = []\n",
        "    previous_word = None\n",
        "    current_word = \"\"\n",
        "    current_label = None\n",
        "\n",
        "    # To present output we need to combine subword tokens (\"hell\",\"##o\" into \"hello\")\n",
        "    for token, pred, offset in zip(tokens, predictions, offset_mapping):\n",
        "        if offset[0] == 0 and offset[1] == 0:\n",
        "            continue\n",
        "\n",
        "        start, end = offset\n",
        "        word = text[start:end]\n",
        "\n",
        "        if token.startswith(\"##\"):\n",
        "            current_word += word\n",
        "        else:\n",
        "            if current_word:\n",
        "                label_name = id2label[current_label] if id2label else current_label\n",
        "                word_entities.append((current_word, label_name))\n",
        "            current_word = word\n",
        "            current_label = pred\n",
        "\n",
        "    if current_word:\n",
        "        label_name = id2label[current_label] if id2label else current_label\n",
        "        word_entities.append((current_word, label_name))\n",
        "\n",
        "    return word_entities\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R0mQ3KUm6FVl",
        "outputId": "21b764db-6af1-46a7-a7d5-43e6182ce87b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input text: अमेरिका की ओर से लगाए गए 104 फ़ीसदी टैरिफ़ पर चीन के राष्ट्रपति शी जिंगपिंग ने अपनी प्रतिक्रिया दी है. शी जिनपिंग ने कहा है कि अमेरिका के टैरिफ़ का सामना करने के लिए चीन को अपने पड़ोसी देशों के साथ रिश्ते मज़बूत करने चाहिए.नए अमेरिकी टैरिफ़ लागू होने के बाद यह पहली बार है जब शी जिंगपिंग ने टैरिफ़ पर बात की है.उन्होंने ये भी कहा कि एशियाई देशों को मिलकर एक बेहतर भविष्य के लिए काम करना होगा. चीन के राष्ट्रपति शी जिनपिंग का ये बयान दक्षिण-पूर्व एशियाई देशों के संगठन आसियान की हालिया टिप्पणी के समान है. आसियान ने भी अपने क्षेत्र में आर्थिक सहयोग बढ़ाने की अपील की थी.वियतनाम, कंबोडिया और इंडोनेशिया पर अमेरिकी टैरिफ़ का सबसे ज़्यादा प्रभाव पड़ा है.\n",
            "Predictions:\n",
            "अमेरिका: B-LOC\n",
            "की: O\n",
            "ओर: O\n",
            "से: O\n",
            "लगाए: O\n",
            "गए: O\n",
            "104: O\n",
            "फ़ीसदी: O\n",
            "टैरिफ़: O\n",
            "पर: O\n",
            "चीन: O\n",
            "के: O\n",
            "राष्ट्रपति: O\n",
            "शी: B-PER\n",
            "जिंगपिंग: I-PER\n",
            "ने: O\n",
            "अपनी: O\n",
            "प्रतिक्रिया: O\n",
            "दी: O\n",
            "है: O\n",
            ".: O\n",
            "शी: B-PER\n",
            "जिनपिंग: I-PER\n",
            "ने: O\n",
            "कहा: O\n",
            "है: O\n",
            "कि: O\n",
            "अमेरिका: O\n",
            "के: O\n",
            "टैरिफ़: O\n",
            "का: O\n",
            "सामना: O\n",
            "करने: O\n",
            "के: O\n",
            "लिए: O\n",
            "चीन: B-LOC\n",
            "को: O\n",
            "अपने: O\n",
            "पड़ोसी: O\n",
            "देशों: O\n",
            "के: O\n",
            "साथ: O\n",
            "रिश्ते: O\n",
            "मज़बूत: O\n",
            "करने: O\n",
            "चाहिए: O\n",
            ".: O\n",
            "नए: O\n",
            "अमेरिकी: O\n",
            "टैरिफ़: O\n",
            "लागू: O\n",
            "होने: O\n",
            "के: O\n",
            "बाद: O\n",
            "यह: O\n",
            "पहली: O\n",
            "बार: O\n",
            "है: O\n",
            "जब: O\n",
            "शी: B-PER\n",
            "जिंगपिंग: I-PER\n",
            "ने: O\n",
            "टैरिफ़: O\n",
            "पर: O\n",
            "बात: O\n",
            "की: O\n",
            "है: O\n",
            ".: O\n",
            "उन्होंने: O\n",
            "ये: O\n",
            "भी: O\n",
            "कहा: O\n",
            "कि: O\n",
            "एशियाई: O\n",
            "देशों: O\n",
            "को: O\n",
            "मिलकर: O\n",
            "एक: O\n",
            "बेहतर: O\n",
            "भविष्य: O\n",
            "के: O\n",
            "लिए: O\n",
            "काम: O\n",
            "करना: O\n",
            "होगा: O\n",
            ".: O\n",
            "चीन: B-LOC\n",
            "के: O\n",
            "राष्ट्रपति: O\n",
            "शी: B-PER\n",
            "जिनपिंग: I-PER\n",
            "का: O\n",
            "ये: O\n",
            "बयान: O\n",
            "दक्षिण: O\n",
            "-: O\n",
            "पूर्व: O\n",
            "एशियाई: O\n",
            "देशों: O\n",
            "के: O\n",
            "संगठन: O\n",
            "आसियान: O\n",
            "की: O\n",
            "हालिया: O\n",
            "टिप्पणी: O\n",
            "के: O\n",
            "समान: O\n",
            "है: O\n",
            ".: O\n",
            "आसियान: O\n",
            "ने: O\n",
            "भी: O\n",
            "अपने: O\n",
            "क्षेत्र: O\n",
            "में: O\n",
            "आर्थिक: O\n",
            "सहयोग: O\n",
            "बढ़ाने: O\n",
            "की: O\n",
            "अपील: O\n",
            "की: O\n",
            "थी: O\n",
            ".: O\n",
            "वियतनाम: O\n",
            ",: O\n",
            "कंबोडिया: O\n",
            "और: O\n",
            "इंडोनेशिया: O\n",
            "पर: O\n",
            "अमेरिकी: O\n",
            "टैरिफ़: O\n",
            "का: O\n",
            "सबसे: O\n",
            "ज़्यादा: O\n",
            "प्रभाव: O\n",
            "पड़ा: O\n",
            "है: O\n",
            ".: O\n"
          ]
        }
      ],
      "source": [
        "#text = \"इटली की पीएम जॉर्जिया मेलोनी ने पूरी दुनिया के लेफ्टिस्ट लीडर्स को पाखंडी बताया है। उन्होंने कहा कि दुनियाभर में मोदी, ट्रम्प और मेरे जैसे दक्षिणपंथी नेताओं के उभरने से सारे लेफ्टिस्ट नेता परेशान हो गए हैं|\"\n",
        "# text = \"भारत की नरेंद्र मोदी सरकार अमेरिकी राष्ट्रपति डॉनल्ड ट्रंप द्वारा लगाए गए 27% आयात शुल्क के खिलाफ किसी भी जवाबी कार्रवाई की योजना फिलहाल नहीं बना रही है. अंतरराष्ट्रीय न्यूज़ एजेंसी रॉयटर्स ने एक वरिष्ठ सरकारी अधिकारी के हवाले से लिखा है कि दिल्ली और वॉशिंगटन डीसी के बीच व्यापार समझौते पर बातचीत जारी है, और इसी कारण भारत संयम बरत रहा है. रिपोर्ट के मुताबिक अधिकारी ने बताया कि केंद्र सरकार डॉनल्ड ट्रंप के टैरिफ ऑर्डर में दिए गए उस प्रावधान का ‘अध्ययन’ कर रही है जिसमें कहा गया है कि जो देश व्यापार को बराबरी पर लाने के लिए सार्थक कदम उठाते हैं, उन्हें छूट दी जा सकती है.\"\n",
        "text = \"अमेरिका की ओर से लगाए गए 104 फ़ीसदी टैरिफ़ पर चीन के राष्ट्रपति शी जिंगपिंग ने अपनी प्रतिक्रिया दी है. \\\n",
        "शी जिनपिंग ने कहा है कि अमेरिका के टैरिफ़ का सामना करने के लिए चीन को अपने पड़ोसी देशों के साथ रिश्ते मज़बूत करने चाहिए.\\\n",
        "नए अमेरिकी टैरिफ़ लागू होने के बाद यह पहली बार है जब शी जिंगपिंग ने टैरिफ़ पर बात की है.\\\n",
        "उन्होंने ये भी कहा कि एशियाई देशों को मिलकर एक बेहतर भविष्य के लिए काम करना होगा. \\\n",
        "चीन के राष्ट्रपति शी जिनपिंग का ये बयान दक्षिण-पूर्व एशियाई देशों के संगठन आसियान की हालिया टिप्पणी के समान है. आसियान ने भी अपने क्षेत्र में आर्थिक सहयोग बढ़ाने की अपील की थी.\\\n",
        "वियतनाम, कंबोडिया और इंडोनेशिया पर अमेरिकी टैरिफ़ का सबसे ज़्यादा प्रभाव पड़ा है.\"\n",
        "predictions = predict_entities(model, tokenizer, text)\n",
        "\n",
        "print(\"Input text:\", text)\n",
        "print(\"Predictions:\")\n",
        "for token, pred in predictions:\n",
        "    print(f\"{token}: {tags.int2str(int(pred))}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6nv4kL9mA4yG"
      },
      "outputs": [],
      "source": [
        "# empty gpu cache\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9kWadNkwBzU6",
        "outputId": "22ff2b5d-8975-40b1-b537-0e3c63a3eab4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Garbage collector to clean unused memory\n",
        "import gc\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3XvtpkVqJz6f",
        "outputId": "9d46ba08-f422-4664-e07b-59fa9a7da883"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  adding: content/SeNER/ (stored 0%)\n",
            "  adding: content/SeNER/special_tokens_map.json (deflated 80%)\n",
            "  adding: content/SeNER/training_args.bin (deflated 52%)\n",
            "  adding: content/SeNER/tokenizer_config.json (deflated 74%)\n",
            "  adding: content/SeNER/tokenizer.json (deflated 70%)\n",
            "  adding: content/SeNER/model.safetensors (deflated 8%)\n",
            "  adding: content/SeNER/vocab.txt (deflated 49%)\n"
          ]
        }
      ],
      "source": [
        "# Zipping model files\n",
        "!zip -r SeNER.zip /content/SeNER"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qw9wS7xPJQ7r"
      },
      "outputs": [],
      "source": [
        "# Download model files\n",
        "from google.colab import files\n",
        "files.download('SeNER.zip')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}